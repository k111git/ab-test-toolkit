# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_wrappers.ipynb.

# %% auto 0
__all__ = ['info', 'hello', 'simulate_evolution_binary', 'realizations_of_evolution_binary', 'plot_realization',
           'plot_snapshots_distribution']

# %% ../nbs/04_wrappers.ipynb 6
def hello():
    print(
        f"""
    Welcome :) \n
    You can find additional documentation here: https://k111git.github.io/ab-test-toolkit/
    """
    )
    pass

# %% ../nbs/04_wrappers.ipynb 8
import numpy as np
import pandas as pd
from .generator import data_to_contingency
from .analyze import p_value_binary
import plotly.io as pio

pio.templates.default = "simple_white"

import plotly.graph_objects as go
import plotly.figure_factory as ff
from plotly.subplots import make_subplots

# %% ../nbs/04_wrappers.ipynb 9
def simulate_evolution_binary(
    N=10000, cr0=0.10, cr1=0.11, snapshot_sizes=np.arange(1000, 10001, 1000)
):
    """
    Simulates the evolution of a binary experiment.
    """
    df = generate_binary_data(N=N, cr0=cr0, cr1=cr1)
    plot_sizes = snapshot_sizes
    result_dfs = []
    for current_size in plot_sizes:
        df1 = df[:current_size]
        df_c = data_to_contingency(df1)
        users0, users1 = df_c.users
        converted0, converted1 = df_c.converted
        rate0, rate1 = df_c.cvr
        ate = rate1 - rate0
        pv = p_value_binary(df_c)
        out_df = pd.DataFrame(
            {
                "size": [current_size],
                "users0": users0,
                "users1": users1,
                "converted0": converted0,
                "converted1": converted1,
                "cr0": rate0,
                "cr1": rate1,
                "pv": [pv],
                "ate": [ate],
            }
        )
        result_dfs.append(out_df)
    result_df = pd.concat(result_dfs)
    return result_df

# %% ../nbs/04_wrappers.ipynb 11
def realizations_of_evolution_binary(
    N_realizations=50,
    N=10000,
    cr0=0.10,
    cr1=0.11,
    snapshot_sizes=np.arange(1000, 10001, 1000),
):
    realizations_df = []
    for i in range(0, N_realizations):
        result_df = simulate_evolution_binary(
            N=N, cr0=cr0, cr1=cr1, snapshot_sizes=snapshot_sizes
        )
        realizations_df.append(result_df)
        if (i % 10) == 0:
            print(f"{i} done")
    print("all done")

    snapshots_df = [
        pd.DataFrame(
            [
                {
                    "realization": i,
                    "ate": realizations_df[i].iloc[j].ate,
                    "pvalue": realizations_df[i].iloc[j].pv,
                }
                for i in range(0, N_realizations)
            ]
        ).sort_values(by="ate")
        for j in range(0, len(snapshot_sizes))
    ]
    return {"dataframes": realizations_df, "snapshots": snapshots_df}

# %% ../nbs/04_wrappers.ipynb 12
def plot_realization(plot_df):
    colors = ["gray", "brown"]
    fig = make_subplots(
        rows=2,
        cols=1,
        specs=[[{"secondary_y": False}], [{"secondary_y": True}]],
    )

    for group in [0, 1]:
        fig.add_trace(
            go.Scatter(
                x=plot_df["size"],
                y=plot_df[f"converted{group}"],
                mode="lines+markers",
                name=f"Group: {group}",
                line_color=colors[group],
                legendgroup="1",
            ),
            row=1,
            col=1,
        )

    fig.add_trace(
        go.Scatter(
            x=plot_df["size"],
            y=plot_df[f"pv"],
            mode="lines+markers",
            name=f"pvalue",
            line_color="cornflowerblue",
            legendgroup="2",
        ),
        row=2,
        col=1,
    )
    fig.add_trace(
        go.Scatter(
            x=plot_df["size"],
            y=-1 * plot_df[f"ate"],
            mode="lines+markers",
            name=f"ate",
            line_color="darkgoldenrod",
            legendgroup="2",
        ),
        row=2,
        col=1,
        secondary_y=True,
    )
    fig.update_yaxes(
        title_text="ate",
        secondary_y=True,
        row=2,
        col=1,
    )
    fig.update_yaxes(
        title_text="pvalue",
        secondary_y=False,
        row=2,
        col=1,
    )
    fig.update_yaxes(
        title_text="Conversions",
        secondary_y=False,
        row=1,
        col=1,
    )

    fig.update_layout(
        height=600,
        width=800,
        title_text="",
        legend_tracegroupgap=180,
    )
    return fig

# %% ../nbs/04_wrappers.ipynb 13
def plot_snapshots_distribution(snapshots, vline_x=None):
    fig = ff.create_distplot(
        [snapshots[j]["ate"] for j in [0, 4, 9]],
        [0, 4, 9],
        show_hist=False,
        show_rug=True,
    )
    if vline_x != None:
        fig.add_vline(
            x=vline_x, line_width=1, line_dash="dash", line_color="gray"
        )

    fig.update_layout(
        template="simple_white",
        xaxis_title="ATE",
        yaxis_title="PDF",
        legend=dict(yanchor="top", y=0.99, xanchor="right", x=0.95),
        height=600,
    )
    fig.update_xaxes(range=[-0.04, 0.04])
    fig.show()

# %% ../nbs/04_wrappers.ipynb 16
info = dict()
info[
    "power"
] = """Statistical power. Usually set to 0.8. This means that if the effect is the minimal effect specified above, we have an 80% probability of correctly identifying it at statistically significant (and hence 20% of not idenfitying it)."""
info[
    "cr1"
] = """Conversion rate variant for minimal detectable effect: cr1 (for example, if we have a conversion rate of 1% and want to detect an effect of at least 20% relate, we would set cr0=0.010 and cr1=0.012)"""
info["cr0"] = """Conversion rate control: cr0"""
info[
    "relative_uplift"
] = f"""Percentage of minimal detectable improvement over the base conversion rate cr0. E.g. if cr0 is 5.0%, a 10% improvement means we would observe a conversion rate of 5.5%."""
info[
    "sided"
] = """As a rule of thumb, if there are very strong reasons to believe that the variant cannot be inferior to the control, we can use a one sided test. In case of doubts, using a two sided test is better.
"""
info[
    "alpha"
] = """Significance threshold: alpha. Usually set to 0.05, this defines our tolerance for falsely detecting an effect if in reality there is none (alpha=0.05 means that in 5% of the cases we will detect an effect even though the samples for control and variant are drawn from the exact same distribution).

"""
info[
    "sigma"
] = """Standard deviation (we assume the same for variant and control, should be estimated from historical data).

"""
info[
    "mu0"
] = """Mean of the control group.

"""
info[
    "mu1"
] = """Mean of the variant group assuming minimal detectable effect (e.g. if the mean it 5, and we want to detect an effect as small as 0.05, mu1=5.00 and mu2=5.05)"""
